{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94f3b74-cdf4-4f45-89dc-a2f8ced14f5d",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd56c3-0cbe-4a46-b724-9b396965658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add langgraph langchain langsmith python-dotenv langchain_ollama langchain_community langchain_tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923b16d-8d37-4757-8a8b-68a1a1e9e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4fa0-fdd0-4d12-b6dc-dc882151b37f",
   "metadata": {},
   "source": [
    "### Tavily Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda9bc9-8a5d-483b-8dbf-fd846a74f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tavily tool\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tool=TavilySearch(max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedd6c6-6596-4ff9-b84d-f9cbca5a4ae1",
   "metadata": {},
   "source": [
    "### Custom Multiply Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0abfce-fba8-44fd-b010-1463bad6d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom function\n",
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): first int if it is in string convert to int\n",
    "        b (int): second int if it is in string convert to int\n",
    "\n",
    "    Returns:\n",
    "        int: result of the multiplication\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f551488-1980-4d4f-b50e-11c38138cdc6",
   "metadata": {},
   "source": [
    "### Create LLM using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd561f-2ea2-4a0b-9ed4-7777f68ace0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaedd86-084d-4f9b-95b5-c864b8cca56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## add tools in llm \n",
    "tools=[search_tool, multiply]\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32cae3-d3f8-4004-8196-dd91b219908c",
   "metadata": {},
   "source": [
    "### Creating the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199a67c-1d37-4a3b-93a7-791e7c5530db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "## State \n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list, add_messages]\n",
    "\n",
    "## Node functionality\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb5dca-1d58-4d3e-857a-183786ae8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Graph\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\",tools_condition)\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "## Compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39055f91-d4f4-4db5-b377-053f6c8db8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24132a6-d9a8-48e8-a516-2fb2f59454fc",
   "metadata": {},
   "source": [
    "### Using this Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba854e1-f379-42dc-933e-6e00c02cb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is the recent AI news for today?\"})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f3272-4601-4a39-b183-07dbe48156b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is 25 multiply by 5?\"})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cfdac-497e-45d3-86d8-748a906f8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is 10 multiply by 5 and then multiply by 2?\"})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f08520-cb9b-4fb1-bf8c-c6567c9bd794",
   "metadata": {},
   "source": [
    "### ReAct Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3dce4-8555-4e4c-9a93-3fc50ced413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Graph\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\",tools_condition)\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "\n",
    "## Compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a07ed3-c3d0-4c80-a398-8981a42aaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1922c-7c46-4fad-85e1-4cb5a8661c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Give me the recent AI news for today and then multiply 10 by 5?\"})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401d3fc-1842-47af-8d2c-e66b52f990c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is 10 multiply by 5 and then multiply by 2?\"})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3421c-c78c-4fe6-afb4-24e9face5539",
   "metadata": {},
   "source": [
    "### Adding Memory In Agentic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a14050-ba02-4d66-b6b9-18736aa95116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "tools=[multiply]\n",
    "llm_with_tools=llm.bind_tools(tools)\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Graph\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\",tools_condition)\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "\n",
    "## Compile the graph\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5911032-d3de-4c87-beeb-140e96576a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "\n",
    "response=graph.invoke({\"messages\":\"Hi, My name is Rahul. How are you?\"},config=config)\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4f115-e257-47d0-a7ce-743c28f6c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Do you remember my name?\"},config=config)\n",
    "\n",
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f522f-31be-42bf-83d2-453ff446042c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
