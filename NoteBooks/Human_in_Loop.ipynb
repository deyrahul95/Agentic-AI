{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a26f117-a48d-4366-9c40-45a3e8d00d73",
   "metadata": {},
   "source": [
    "# Human Feedback in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f39d8-e0aa-4254-bb4a-a855b058b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ac45d-b015-4c33-8304-b3f491f76151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create memory for LLM\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory=MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b44f1-f7b0-4047-9fe3-a3be2df38bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create State\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebbf1f-27c1-4cd1-a765-14382cf24584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "## Create graph builder\n",
    "graph_builder=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e35d2-d6ed-49fa-b19b-aa77d399837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Human Assistance Tool\n",
    "@tool\n",
    "def human_assistance(query:str) -> str:\n",
    "    \"\"\"Use this tool if assistance is requested from a user.\"\"\"\n",
    "    human_response = interrupt({ \"query\": query })\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "\n",
    "## Multiply Tool\n",
    "@tool\n",
    "def multiply(a:int,b:int) -> int:\n",
    "    \"\"\"\n",
    "    Multiple two numbers\n",
    "    \n",
    "    a: first int\n",
    "    b: second int\n",
    "\n",
    "    Retruns:\n",
    "        int result of multiplication\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "tools = [multiply, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658f82c-fddc-4607-ad49-f6723acbe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Graph\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21092f-725e-4904-b3c9-b69ebd765de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131b690-74f5-417f-a8b9-daaa404f2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I need some expert guidance and assistance for building my AI Agent. could you request assistance for me?\"\n",
    "\n",
    "events = graph.stream({\"messages\":user_input},\n",
    "                      config,\n",
    "                      stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cae2c-668e-4ba5-b9c9-87b5a8e7f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \"It's much more reliable and extensible than simple automation agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, \n",
    "                      config, \n",
    "                      stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce443921-26e5-4f86-9359-eec16d54f98f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
